{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "HOME_PATH = '/home/shubhams/Hercules/kidstube-data/video_splits/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all video directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_directories = []\n",
    "for file in os.listdir('/home/shubhams/Hercules/kidstube-data/videos/'):\n",
    "    file = file.split('.')[0]\n",
    "    frame_directories.append(os.path.join(HOME_PATH, file, 'frames_6fps/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def read_image(img_path):\n",
    "    if os.path.isfile(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        return np.asarray(img)\n",
    "    else:\n",
    "        return np.zeros((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "# vgg16.classifier = nn.Sequential(*list(vgg16.classifier.children())[:-2])\n",
    "layers = list(vgg16.features.children())\n",
    "layers.append(nn.AdaptiveMaxPool2d(1))\n",
    "modified_vgg16 = nn.Sequential(*layers)\n",
    "for p in modified_vgg16.parameters():\n",
    "    p.requires_grad = False\n",
    "modified_vgg16.eval()\n",
    "if use_cuda:\n",
    "    modified_vgg16.cuda()\n",
    "print(modified_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "normalizer = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "def get_vgg_features_from_frame(frame_paths):\n",
    "    tensor_list = []\n",
    "    for frame_path in frame_paths:\n",
    "        frame = read_image(frame_path)\n",
    "        normalized_frame = normalizer(frame)\n",
    "        normalized_frame = normalized_frame.unsqueeze(0)\n",
    "        tensor_list.append(normalized_frame)\n",
    "    frame_tensors = Variable(torch.cat(tensor_list, 0))\n",
    "    if use_cuda:\n",
    "        frame_tensors = frame_tensors.cuda()\n",
    "    frame_features = modified_vgg16(frame_tensors)\n",
    "    frame_features = frame_features.view(frame_features.shape[0], frame_features.shape[1])\n",
    "    np_frame_features = frame_features.cpu().data.numpy()\n",
    "    start = np_frame_features.shape[0]\n",
    "    for i in range(start, 6):\n",
    "        np_frame_features = np.insert(np_frame_features, i, 0, axis=0)\n",
    "    return np_frame_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data as HDF5 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_checkpoint(frame_data, video_ids, path='/home/shubhams/Hercules/kidstube-data/processed/aggregate_1_sec/frames_features.hdf5'):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "    with h5py.File(path, 'a', libver='latest') as f:\n",
    "        frame_data = np.array(frame_data)\n",
    "        video_ids = np.array(video_ids)\n",
    "        \n",
    "        try:\n",
    "            frame_dset = f['frames']\n",
    "            vids_dset = f['vids']\n",
    "        except KeyError:\n",
    "            frame_dset = f.create_dataset('frames', shape=(0, 6, 512), maxshape=(None, 6, 512), compression = 'gzip')\n",
    "            vids_dset = f.create_dataset('vids', shape=(0, ), maxshape=(None, ), compression = 'gzip', dtype=h5py.special_dtype(vlen=str))\n",
    "            f.swmr_mode = True\n",
    "\n",
    "        new_frame_shape = frame_data.shape[0]\n",
    "        new_vids_shape = video_ids.shape[0]\n",
    "        \n",
    "        frame_dset.resize(frame_dset.shape[0] + new_frame_shape, axis=0)\n",
    "        vids_dset.resize(vids_dset.shape[0] + new_vids_shape, axis=0)\n",
    "        \n",
    "        frame_dset[-new_frame_shape:] = frame_data\n",
    "        vids_dset[-new_vids_shape:] = video_ids\n",
    "        print(frame_dset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in frame_directories:\n",
    "    features = []\n",
    "    vids = []\n",
    "    frame_files = natural_sort(glob.glob(directory+'*.jpg'))\n",
    "    frame_files_per_second = list(chunks(frame_files, 6))\n",
    "    ctr = 0\n",
    "    for frames_per_second in frame_files_per_second:\n",
    "        if len(frames_per_second) > 3:\n",
    "            frame_features = get_vgg_features_from_frame(frames_per_second)\n",
    "            features.append(frame_features)\n",
    "            vids.append(directory.split(os.sep)[-3])\n",
    "            print(ctr)\n",
    "            ctr += 1\n",
    "#     save_checkpoint(features, vids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kidstube2]",
   "language": "python",
   "name": "conda-env-kidstube2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
